{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. The output is saved as 'data/autalic_processed.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/AUTALIC.csv\")\n",
    "\n",
    "# Define a function to determine the truth value based on annotator agreement\n",
    "def determine_truth(row):\n",
    "    scores = [row['A1_Score'], row['A2_Score'], row['A3_Score']]\n",
    "    # Count the occurrences of each score\n",
    "    counts = {score: scores.count(score) for score in set(scores)}\n",
    "    # Find the score that has two or more agreements\n",
    "    for score, count in counts.items():\n",
    "        if count >= 2:\n",
    "            return score\n",
    "    # If all three annotators disagree, return -1\n",
    "    return -1\n",
    "\n",
    "# Apply the function and create the 'truth' column\n",
    "df['truth'] = df.apply(determine_truth, axis=1)\n",
    "\n",
    "# Save the processed dataset\n",
    "df.to_csv(\"data/autalic_processed.csv\", index=False)\n",
    "\n",
    "print(\"Processing complete. The output is saved as 'data/autalic_processed.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>llama3<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence 1/5: Our vision is to provide meaningful employment opportunities for individuals with Down syndrome and other disabilities fostering a space where they can showcase their talents and skills in the heart of our local community\n",
      "Processing sentence 2/5: It doesnt matter if you actually know autistic people with similar traits or if you know an expert only Jordan can know whats going on in his head\n",
      "Processing sentence 3/5: a11y supporthttpa11ysupportio is a communitydriven website that aims to help inform developers about what is accessibility supportedhttpswwww3orgTRWCAGcc4\n",
      "Processing sentence 4/5: There have been times where I have acted quiet when I didnt know what to say or was socially clueless and this might explain why many autistic guys I meet do this far more often than me because they struggle socially more than even me and I struggle socially way too much anyway\n",
      "Processing sentence 5/5: I know we have a few ASD parents in here and as one of them its offensive AF and unlike the rest Im gonna call it out when I see it\n",
      "Processing complete. Results saved to outputs/autalic_llama3_result.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/autalic_test.csv\")\n",
    "\n",
    "# Initialize an empty list to store Llama 3's responses\n",
    "llama3_responses = []\n",
    "\n",
    "# Function to query Llama 3 using `ollama run` and enforce consistent short responses\n",
    "def ask_llama3(sentence):\n",
    "    prompt = (\n",
    "        f\"Answer whether the following sentence is ableist with only one of the following responses: \"\n",
    "        f\"'Ableist', 'Not ableist', or 'Needs more context'.\\n\"\n",
    "        f\"Sentence: \\\"{sentence}\\\"\"\n",
    "    )\n",
    "    try:\n",
    "        # Call the Ollama CLI using the `run` command\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", \"llama3\"],\n",
    "            input=prompt,\n",
    "            text=True,\n",
    "            capture_output=True,\n",
    "        )\n",
    "        \n",
    "        # Get the output and strip any extra whitespace\n",
    "        response = result.stdout.strip()\n",
    "        \n",
    "        # Ensure the response is one of the valid categories\n",
    "        valid_responses = ['Ableist', 'Not ableist', 'Needs more context']\n",
    "        if response in valid_responses:\n",
    "            return response\n",
    "        else:\n",
    "            print(f\"Unexpected response: '{response}' for sentence: {sentence}\")\n",
    "            return \"Needs more context\"  # Default to 'Needs more context' if unexpected response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying Llama 3 for sentence: {sentence}\\n{e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "# Ensure the 'outputs' folder exists\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "# Loop through each sentence and query Llama 3\n",
    "for idx, sentence in enumerate(df['Sentence'], 1):\n",
    "    print(f\"Processing sentence {idx}/{len(df)}: {sentence}\")\n",
    "    response = ask_llama3(sentence)\n",
    "    llama3_responses.append(response)\n",
    "\n",
    "# Add the responses to the dataframe\n",
    "df['llama3_response'] = llama3_responses\n",
    "\n",
    "# Save the updated dataset\n",
    "output_file = \"outputs/autalic_llama3_result.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processing complete. Results saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>gpt-4<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence 1/5: Our vision is to provide meaningful employment opportunities for individuals with Down syndrome and other disabilities fostering a space where they can showcase their talents and skills in the heart of our local community\n",
      "Error querying GPT-4 for sentence: Our vision is to provide meaningful employment opportunities for individuals with Down syndrome and other disabilities fostering a space where they can showcase their talents and skills in the heart of our local community\n",
      "'Chat' object has no attribute 'Completion'\n",
      "Processing sentence 2/5: It doesnt matter if you actually know autistic people with similar traits or if you know an expert only Jordan can know whats going on in his head\n",
      "Error querying GPT-4 for sentence: It doesnt matter if you actually know autistic people with similar traits or if you know an expert only Jordan can know whats going on in his head\n",
      "'Chat' object has no attribute 'Completion'\n",
      "Processing sentence 3/5: a11y supporthttpa11ysupportio is a communitydriven website that aims to help inform developers about what is accessibility supportedhttpswwww3orgTRWCAGcc4\n",
      "Error querying GPT-4 for sentence: a11y supporthttpa11ysupportio is a communitydriven website that aims to help inform developers about what is accessibility supportedhttpswwww3orgTRWCAGcc4\n",
      "'Chat' object has no attribute 'Completion'\n",
      "Processing sentence 4/5: There have been times where I have acted quiet when I didnt know what to say or was socially clueless and this might explain why many autistic guys I meet do this far more often than me because they struggle socially more than even me and I struggle socially way too much anyway\n",
      "Error querying GPT-4 for sentence: There have been times where I have acted quiet when I didnt know what to say or was socially clueless and this might explain why many autistic guys I meet do this far more often than me because they struggle socially more than even me and I struggle socially way too much anyway\n",
      "'Chat' object has no attribute 'Completion'\n",
      "Processing sentence 5/5: I know we have a few ASD parents in here and as one of them its offensive AF and unlike the rest Im gonna call it out when I see it\n",
      "Error querying GPT-4 for sentence: I know we have a few ASD parents in here and as one of them its offensive AF and unlike the rest Im gonna call it out when I see it\n",
      "'Chat' object has no attribute 'Completion'\n",
      "Processing complete. Results saved to outputs/autalic_gpt4_result.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key (load from environment or .env file)\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Assumed to be set in environment variables\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/autalic_test.csv\")\n",
    "\n",
    "# Initialize an empty list to store GPT-4's responses\n",
    "gpt4_responses = []\n",
    "\n",
    "# Function to query GPT-4 using the OpenAI API and enforce consistent short responses\n",
    "def ask_gpt4(sentence):\n",
    "    prompt = (\n",
    "        f\"Answer whether the following sentence is ableist with only one of the following responses: \"\n",
    "        f\"'Ableist', 'Not ableist', or 'Needs more context'.\\n\"\n",
    "        f\"Sentence: \\\"{sentence}\\\"\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Use the correct method `openai.ChatCompletion.create()` to interact with GPT-4\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=10,  # Keep response short\n",
    "            temperature=0,  # Make the output more deterministic\n",
    "            top_p=1,  # Use the top token probability\n",
    "            n=1,  # Only one response\n",
    "            stop=None  # Don't use a stop sequence\n",
    "        )\n",
    "        \n",
    "        # Get the model's response and strip extra whitespace\n",
    "        model_response = response['choices'][0]['message']['content'].strip()\n",
    "        \n",
    "        # Ensure the response is one of the valid categories\n",
    "        valid_responses = ['Ableist', 'Not ableist', 'Needs more context']\n",
    "        if model_response in valid_responses:\n",
    "            return model_response\n",
    "        else:\n",
    "            print(f\"Unexpected response: '{model_response}' for sentence: {sentence}\")\n",
    "            return \"Needs more context\"  # Default to 'Needs more context' if unexpected response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying GPT-4 for sentence: {sentence}\\n{e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "# Ensure the 'outputs' folder exists\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "# Loop through each sentence and query GPT-4\n",
    "for idx, sentence in enumerate(df['Sentence'], 1):\n",
    "    print(f\"Processing sentence {idx}/{len(df)}: {sentence}\")\n",
    "    response = ask_gpt4(sentence)\n",
    "    gpt4_responses.append(response)\n",
    "\n",
    "# Add the responses to the dataframe\n",
    "df['gpt4_response'] = gpt4_responses\n",
    "\n",
    "# Save the updated dataset\n",
    "output_file = \"outputs/autalic_gpt4_result.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processing complete. Results saved to {output_file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
